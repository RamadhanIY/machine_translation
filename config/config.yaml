# Model parameters
latent_dim: 256
maxlength: 50
num_encoder_tokens: 10000
num_decoder_tokens: 10000
indo_vocab_size: 10000

# Training parameters
batch_size: 64
epochs: 100
learning_rate: 0.001
optimizer: Adam
loss: categorical_crossentropy
metrics:
  - masked_accuracy
  - accuracy

# Model architecture
attention: true
# # File paths
# train_data_path: path/to/train/data
# val_data_path: path/to/validation/data
# test_data_path: path/to/test/data

# # Checkpoints and logs
# checkpoint_path: path/to/checkpoints
# log_dir: path/to/logs